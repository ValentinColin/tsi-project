{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "689722e0-edfe-4baa-96c3-4bb4dfd2a4a5",
   "metadata": {},
   "source": [
    "# Preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a99420e5-6b13-4ee6-926a-5ecc65146f3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-launching as admin!\n"
     ]
    }
   ],
   "source": [
    "import pyuac\n",
    "\n",
    "def main():\n",
    "    print(\"Do stuff here that requires being run as an admin.\")\n",
    "    # The window will disappear as soon as the program exits!\n",
    "    input(\"Press enter to close the window. >\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not pyuac.isUserAdmin():\n",
    "        print(\"Re-launching as admin!\")\n",
    "        pyuac.runAsAdmin()\n",
    "    else:        \n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5c6c77c-9c8e-4c9e-8c86-c5ac7ca823c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d561f4c-bdf4-476e-bb1d-993844b996cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasks = ['emoji', 'emotion', 'hate', 'irony', 'offensive', 'sentiment', 'sentiment-latest']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034c8a11-6e76-44df-81f5-a59df883660d",
   "metadata": {},
   "source": [
    "# Process Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35625fc4-0bb7-4042-982a-898894b4e89b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    " \n",
    " \n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aad9eda-2d3d-4778-9489-fda226fafb1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_labels(task):\n",
    "    # download label mapping\n",
    "    labels=[]\n",
    "    mapping_link = f\"./cardiffnlp/twitter-roberta-base-{task}/mapping.txt\"\n",
    "    with open(mapping_link, encoding=\"utf-8\") as f:\n",
    "        maps = f.read().split(\"\\n\")\n",
    "        csvreader = csv.reader(maps, delimiter='\\t')\n",
    "    labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65ea4c8f-dddc-4c83-b198-076a72b53049",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_analysis(task, text):\n",
    "    labels = get_labels(task)\n",
    "    MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "    \n",
    "    text = preprocess(text)\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    \n",
    "    ranking = np.argsort(scores)\n",
    "    ranking = ranking[::-1]\n",
    "    print(f\"According to our {task} model, this tweet is :\")\n",
    "\n",
    "    for i in range(scores.shape[0]):\n",
    "        l = labels[ranking[i]]\n",
    "        s = scores[ranking[i]]\n",
    "        print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392b74fc-9b7c-463e-956c-bb24bc3b75f2",
   "metadata": {},
   "source": [
    "# Let's Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79e7ef36-745b-4cf7-a11d-1ce2d6c027f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to our emoji model, this tweet is :\n",
      "1) 😍 0.6581\n",
      "2) 😊 0.0618\n",
      "3) ❤ 0.0598\n",
      "4) 😂 0.0373\n",
      "5) 💕 0.0353\n",
      "6) 💙 0.0295\n",
      "7) 😁 0.0261\n",
      "8) 💜 0.0204\n",
      "9) 😘 0.0193\n",
      "10) ✨ 0.0105\n",
      "11) 😎 0.0102\n",
      "12) 🔥 0.0088\n",
      "13) 😉 0.0064\n",
      "14) 😜 0.0055\n",
      "15) 🎄 0.0032\n",
      "16) 💯 0.0026\n",
      "17) 🇺🇸 0.0018\n",
      "18) 📷 0.0015\n",
      "19) 📸 0.0011\n",
      "20) ☀ 0.0008\n",
      "According to our emotion model, this tweet is :\n",
      "1) joy 0.9542\n",
      "2) optimism 0.0177\n",
      "3) anger 0.0145\n",
      "4) sadness 0.0136\n",
      "According to our hate model, this tweet is :\n",
      "1) not-hate 0.9523\n",
      "2) hate 0.0477\n",
      "According to our irony model, this tweet is :\n",
      "1) irony 0.9348\n",
      "2) non_irony 0.0652\n",
      "According to our offensive model, this tweet is :\n",
      "1) not-offensive 0.8711\n",
      "2) offensive 0.1289\n",
      "According to our sentiment model, this tweet is :\n",
      "1) positive 0.9846\n",
      "2) neutral 0.0132\n",
      "3) negative 0.0021\n",
      "According to our sentiment-latest model, this tweet is :\n",
      "1) positive 0.9868\n",
      "2) neutral 0.009\n",
      "3) negative 0.0042\n"
     ]
    }
   ],
   "source": [
    "tweet = \"My IA teacher is so handsome !\"\n",
    "\n",
    "for task in tasks:\n",
    "    get_analysis(task, tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2dc53da-2d7b-4aa6-9cd2-ede1a8ea2d91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGood night 😊\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m text \u001b[38;5;241m=\u001b[39m preprocess(text)\n\u001b[1;32m----> 8\u001b[0m encoded_input \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m output \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoded_input)\n\u001b[0;32m     10\u001b[0m scores \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# PT\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.save_pretrained(MODEL)\n",
    "\n",
    "text = \"Good night 😊\"\n",
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "# # TF\n",
    "# model = TFAutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "# model.save_pretrained(MODEL)\n",
    "\n",
    "# text = \"Good night 😊\"\n",
    "# encoded_input = tokenizer(text, return_tensors='tf')\n",
    "# output = model(encoded_input)\n",
    "# scores = output[0][0].numpy()\n",
    "# scores = softmax(scores)\n",
    "\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = labels[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50e8717-a571-436c-aecb-90e7cbca51e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PT\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-irony\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.save_pretrained(MODEL)\n",
    "\n",
    "text = \"Good night 😊\"\n",
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "# # TF\n",
    "# model = TFAutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "# model.save_pretrained(MODEL)\n",
    "\n",
    "# text = \"Good night 😊\"\n",
    "# encoded_input = tokenizer(text, return_tensors='tf')\n",
    "# output = model(encoded_input)\n",
    "# scores = output[0][0].numpy()\n",
    "# scores = softmax(scores)\n",
    "\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = labels[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
