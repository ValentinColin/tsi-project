{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a99420e5-6b13-4ee6-926a-5ecc65146f3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-launching as admin!\n"
     ]
    }
   ],
   "source": [
    "import pyuac\n",
    "\n",
    "def main():\n",
    "    print(\"Do stuff here that requires being run as an admin.\")\n",
    "    # The window will disappear as soon as the program exits!\n",
    "    input(\"Press enter to close the window. >\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not pyuac.isUserAdmin():\n",
    "        print(\"Re-launching as admin!\")\n",
    "        pyuac.runAsAdmin()\n",
    "    else:        \n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5c6c77c-9c8e-4c9e-8c86-c5ac7ca823c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35625fc4-0bb7-4042-982a-898894b4e89b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    " \n",
    " \n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1a97e28-6719-448d-a6aa-ad4998375bf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emoji\n",
      "emotion\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce135426c0cd444087394776eba4f503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hate\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8891b93d62be4c7b9e537e0fc2ad63fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "irony\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2209f5a4564fda9ceebc7eb0d34a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "offensive\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63bedb488d5c4e0497dae35118912646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n"
     ]
    }
   ],
   "source": [
    "tasks = ['emoji', 'emotion', 'hate', 'irony', 'offensive', 'sentiment', 'sentiment-latest']\n",
    "for task in tasks:\n",
    "    print(task)\n",
    "    MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "    tokenizer.save_pretrained(MODEL)\n",
    "    model.save_pretrained(MODEL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1aad9eda-2d3d-4778-9489-fda226fafb1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_labels(task):\n",
    "    # download label mapping\n",
    "    labels=[]\n",
    "    mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "    with urllib.request.urlopen(mapping_link) as f:\n",
    "        html = f.read().decode('utf-8').split(\"\\n\")\n",
    "        csvreader = csv.reader(html, delimiter='\\t')\n",
    "    labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65ea4c8f-dddc-4c83-b198-076a72b53049",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_analysis(task, text):\n",
    "    labels = get_labels(task)\n",
    "    MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "    \n",
    "    text = preprocess(text)\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    \n",
    "    ranking = np.argsort(scores)\n",
    "    ranking = ranking[::-1]\n",
    "    print(f\"According to our {task} model, this tweet is :\")\n",
    "\n",
    "    for i in range(scores.shape[0]):\n",
    "        l = labels[ranking[i]]\n",
    "        s = scores[ranking[i]]\n",
    "        print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79e7ef36-745b-4cf7-a11d-1ce2d6c027f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to our emoji model, this tweet is :\n",
      "1) 😂 0.4513\n",
      "2) 😁 0.1495\n",
      "3) 😜 0.0924\n",
      "4) 😉 0.0856\n",
      "5) 😊 0.0813\n",
      "6) 😎 0.0553\n",
      "7) 😍 0.0203\n",
      "8) 🔥 0.0095\n",
      "9) 😘 0.0077\n",
      "10) ❤ 0.0075\n",
      "11) 💯 0.0071\n",
      "12) ✨ 0.0061\n",
      "13) 🇺🇸 0.0041\n",
      "14) 📷 0.0038\n",
      "15) 💕 0.0037\n",
      "16) 💜 0.0035\n",
      "17) 💙 0.0034\n",
      "18) 📸 0.0032\n",
      "19) 🎄 0.0028\n",
      "20) ☀ 0.0019\n",
      "According to our emotion model, this tweet is :\n",
      "1) anger 0.9484\n",
      "2) sadness 0.0372\n",
      "3) joy 0.009\n",
      "4) optimism 0.0054\n",
      "According to our hate model, this tweet is :\n",
      "1) not-hate 0.9682\n",
      "2) hate 0.0318\n",
      "According to our irony model, this tweet is :\n",
      "1) irony 0.9736\n",
      "2) non_irony 0.0264\n",
      "According to our offensive model, this tweet is :\n",
      "1) offensive 0.5013\n",
      "2) not-offensive 0.4987\n",
      "According to our sentiment model, this tweet is :\n",
      "1) negative 0.7745\n",
      "2) neutral 0.191\n",
      "3) positive 0.0345\n"
     ]
    }
   ],
   "source": [
    "tweet = \"Great I get fired for grossophobia...\"\n",
    "\n",
    "for task in tasks:\n",
    "    get_analysis(task, tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b08097-a186-442a-9724-520fb4336b18",
   "metadata": {},
   "source": [
    "## Sentiment Latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dc53da-2d7b-4aa6-9cd2-ede1a8ea2d91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PT\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.save_pretrained(MODEL)\n",
    "\n",
    "text = \"Good night 😊\"\n",
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "# # TF\n",
    "# model = TFAutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "# model.save_pretrained(MODEL)\n",
    "\n",
    "# text = \"Good night 😊\"\n",
    "# encoded_input = tokenizer(text, return_tensors='tf')\n",
    "# output = model(encoded_input)\n",
    "# scores = output[0][0].numpy()\n",
    "# scores = softmax(scores)\n",
    "\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = labels[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50e8717-a571-436c-aecb-90e7cbca51e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PT\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-irony\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.save_pretrained(MODEL)\n",
    "\n",
    "text = \"Good night 😊\"\n",
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "# # TF\n",
    "# model = TFAutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "# model.save_pretrained(MODEL)\n",
    "\n",
    "# text = \"Good night 😊\"\n",
    "# encoded_input = tokenizer(text, return_tensors='tf')\n",
    "# output = model(encoded_input)\n",
    "# scores = output[0][0].numpy()\n",
    "# scores = softmax(scores)\n",
    "\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = labels[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
